{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "567cf2cd",
   "metadata": {},
   "source": [
    "# TEMAS - Turkey Earthquake Monitoring and Analysis System\n",
    "\n",
    "### ==== Version: 0.7.1 released on 12 March 2023 by Marcus Zou ====\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0dfb86",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "\n",
    "- The origin data table is embedded/nested at http://www.koeri.boun.edu.tr/sismo/2/latest-earthquakes/automatic-solutions/, \n",
    "- being updated daily per events happened in Turkey and surounding areas.\n",
    "\n",
    "- From 16 Jan 2023 and onwards, I started to grab down the dataset daily and manually, \n",
    "- and put/merge into a csv file named \"data/koeri.boun.edu.tr-lasteq-autosol_from_2023-01-16_tab.csv\". \n",
    "- This is a very time consuming.\n",
    "\n",
    "\n",
    "## Progress\n",
    "\n",
    "#### v0.7.1 build 2023-03-12\n",
    "* Dockerized the project into a cloud service\n",
    "* Scheduled a Data Updater\n",
    "\n",
    "#### v0.7.0 build 2023-03-11\n",
    "* Failed to add Choropleth map due to lack of decent geojson file per province.\n",
    "* Re-org the project files and folders prior to deployment.\n",
    "  \n",
    "#### v0.6.0 build 2023-03-10\n",
    "* Split the jobs (Daily Job Runner + Mapper)\n",
    "* Designed and Made a landing page (index.html) and other pages.\n",
    "\n",
    "#### v0.5.0 build 2023-03-09\n",
    "* Organized the all-in-one Jupyter Notebook: db-reader + scrapper + merger + mapper.\n",
    "\n",
    "#### v0.4.1 build 2023-03-08\n",
    "* Scraping the multiple pages from koeri.boun.edu.tr was successful.\n",
    "* http://sc3.koeri.boun.edu.tr/eqevents/events1.html\n",
    "* http://sc3.koeri.boun.edu.tr/eqevents/events2.html\n",
    "* ...\n",
    "* http://sc3.koeri.boun.edu.tr/eqevents/events32.html\n",
    "* http://sc3.koeri.boun.edu.tr/eqevents/events33.html\n",
    "\n",
    "#### v0.4.0 build 2023-03-07\n",
    "* Scraping the first page from koeri.boun.edu.tr was successful.\n",
    "* http://sc3.koeri.boun.edu.tr/eqevents/events.html\n",
    "\n",
    "#### v0.3.0 build 2023-03-04\n",
    "* Created a SQLite3 db and saved the dataframe of Historic data into it.\n",
    "\n",
    "#### v0.2.1 build 2023-02-27\n",
    "* Merged historic and real-time data into one local dataframe.\n",
    "\n",
    "#### v0.2.0 build 2023-02-26\n",
    "* Historic database added (from 16 Jan 2023).\n",
    "\n",
    "#### v0.1.0 build 2023-02-13\n",
    "* First release - current 500 datapoints only.\n",
    "\n",
    "\n",
    "## Planning\n",
    "\n",
    "Thinking about -\n",
    "* to load up the historic data - Done!\n",
    "* to build a local database (SQLite3?) to save what we have grabbed down so far - Done!\n",
    "* to run a webScraping task to grab down the daily updates from the website mentioned above - Done!\n",
    "* to merge the historic dataset and the realtime daily updates into one database - Done!\n",
    "<br><br>\n",
    "* Finnally implement this into .py files and schedule daily job-runner - Done!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca93b148",
   "metadata": {},
   "source": [
    "## PART 0. Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf158b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium import plugins\n",
    "import branca\n",
    "import geocoder\n",
    "import reverse_geocoder as rg\n",
    "import webbrowser\n",
    "import datetime as dt\n",
    "import sqlite3\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "print('Pandas: ', pd.__version__)\n",
    "print('Folium: ', folium.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3c5f90",
   "metadata": {},
   "source": [
    "## PART 1. Web Scrapping Real-time Data\n",
    "\n",
    "\n",
    "More in-depth digging reveals that the actual tables are in HTML format as below (34 counts):\n",
    "\n",
    "* http://sc3.koeri.boun.edu.tr/eqevents/events.html\n",
    "* http://sc3.koeri.boun.edu.tr/eqevents/events1.html\n",
    "* http://sc3.koeri.boun.edu.tr/eqevents/events2.html\n",
    "* ...\n",
    "* http://sc3.koeri.boun.edu.tr/eqevents/events32.html\n",
    "* http://sc3.koeri.boun.edu.tr/eqevents/events33.html\n",
    "\n",
    "Then the target page is being reset to: http://sc3.koeri.boun.edu.tr/eqevents/events{i}.html and \n",
    "the scrapping task focus on the first a few pages if the job runner be turned on every day.\n",
    "\n",
    "It turns out the first page naming convention **differs** from the rest, then we have to scrap them into seperate dataframes and merge the two.\n",
    "\n",
    "Then merge the dataframe to the SQLite3 database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27642727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send a GET request to the URL - the first page\n",
    "url0 = \"http://sc3.koeri.boun.edu.tr/eqevents/events.html\"\n",
    "response = requests.get(url0)\n",
    "# parse the HTML content of the page with BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "data0 = []\n",
    "# find the table element and iterate over its rows\n",
    "table = soup.find(\"table\", {'class': 'index'})\n",
    "rows = table.find_all(\"tr\", {'class': 'trIndevnrow'})[1:]\n",
    "for row in rows:\n",
    "    # get the cells in the row\n",
    "    cols = row.find_all(\"td\")\n",
    "    # get the earthquake information from the columns\n",
    "    origintimeutc = cols[0].text.strip()\n",
    "    magnitude = cols[1].text.strip()\n",
    "    magType = cols[2].text.strip()\n",
    "    lat = cols[3].text.strip()\n",
    "    long = cols[4].text.strip()\n",
    "    depth = cols[5].text.strip()\n",
    "    region = cols[6].text.strip()\n",
    "    am = cols[7].text.strip()\n",
    "    lastUpd = cols[8].text.strip()\n",
    "    kml = cols[9].text.strip()\n",
    "    \n",
    "    data0.append([origintimeutc, magnitude, magType, lat, long, depth, region, am, lastUpd, kml])\n",
    "        \n",
    "df0 = pd.DataFrame(data0, columns=['origintimeutc', 'magnitude', 'magType', 'latitude', 'longitude', 'depthKM', 'region', 'measMethod', 'updTime', 'attribute'])\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd5549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Multiple Pages\n",
    "data1 = []\n",
    "# loop through the pages 1-5\n",
    "for i in range(1,9):\n",
    "    # specify the URL to scrape\n",
    "    url = f\"http://sc3.koeri.boun.edu.tr/eqevents/events{i}.html\"\n",
    "    \n",
    "    # make a GET request to the URL and get the HTML content\n",
    "    response = requests.get(url)\n",
    "    html_content = response.content\n",
    "    \n",
    "    # parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # find the earthquake table\n",
    "    eq_table = soup.find('table', {'class': 'index'})\n",
    "    \n",
    "    # loop through the rows of the table\n",
    "    for row in eq_table.find_all('tr', {'class': 'trIndevnrow'})[1:]:\n",
    "        # get the columns of the row\n",
    "        cols = row.find_all('td')\n",
    "        \n",
    "        # get the earthquake information from the columns\n",
    "        origintimeutc = cols[0].text.strip()\n",
    "        magnitude = cols[1].text.strip()\n",
    "        magType = cols[2].text.strip()\n",
    "        lat = cols[3].text.strip()\n",
    "        long = cols[4].text.strip()\n",
    "        depth = cols[5].text.strip()\n",
    "        region = cols[6].text.strip()\n",
    "        am = cols[7].text.strip()\n",
    "        lastUpd = cols[8].text.strip()\n",
    "        kml = cols[9].text.strip()\n",
    "        \n",
    "        data1.append([origintimeutc, magnitude, magType, lat, long, depth, region, am, lastUpd, kml])\n",
    "               \n",
    "df1 = pd.DataFrame(data1, columns = [\"origintimeutc\", \"magnitude\", \"magType\", \"latitude\", \"longitude\", \"depthKM\", \"region\", \"measMethod\", \"updTime\", \"attribute\"])\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate 2 realtime dataframes\n",
    "rtDF = pd.concat([df0, df1]).drop_duplicates(subset='origintimeutc', keep='last')\n",
    "# Reset the Index\n",
    "rtDF = rtDF.reset_index(drop=True)\n",
    "rtDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c50006",
   "metadata": {},
   "source": [
    "## PART 2. Load Historic Data from Local Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aeaed3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a connection to the databse\n",
    "conn = sqlite3.connect('data/earthquake-in-turkey.db')\n",
    "\n",
    "# Read out the whole dataset as dataframe\n",
    "histDF = pd.read_sql_query(\"SELECT * FROM quaketk\", conn)\n",
    "histDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf134505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the last timestamp of the Historic database\n",
    "cutoff_time = histDF['origintimeutc'].max()\n",
    "print('The newest timestamp in Historic database is:', cutoff_time)\n",
    "\n",
    "# Subset the Realtime DF per the last record in the Historic Database\n",
    "rtDF = rtDF[rtDF['origintimeutc'] > cutoff_time]\n",
    "\n",
    "# Sort the DF to be the format of: Older datapoint to be inserted firstly\n",
    "rtDF1 = rtDF.sort_values(by='origintimeutc', ascending=True)\n",
    "rtDF1.reset_index(drop=True, inplace=True)\n",
    "rtDF1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e645623",
   "metadata": {},
   "source": [
    "## PART 3. Merge/Insert Realtime DF into Historic Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd71ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to database\n",
    "rtDF1.columns = ['origintimeutc', 'magnitude', 'magtype', 'latitude', 'longitude', 'depthkm', 'region', 'measmethod', 'updtime', 'attribute']\n",
    "rtDF1.to_sql('quaketk', conn, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if the dataframe has been saved to sqlite DB or not, please uncomment the following command\n",
    "#conn.execute('SELECT * from quaketk ORDER BY origintimeutc DESC LIMIT 20').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf3fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloe the Database\n",
    "conn.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a00b7ba",
   "metadata": {},
   "source": [
    "## PART 4. Retrieve the Whole Dataset for Export and Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2238c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup pandas display template\n",
    "pd.set_option('display.width', 960)\n",
    "pd.set_option('display.max_columns', 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28634c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection to the databse\n",
    "conn = sqlite3.connect('data/earthquake-in-turkey.db')\n",
    "\n",
    "# Read out the whole dataset as dataframe\n",
    "df_d = pd.read_sql_query(\"SELECT * FROM quaketk\", conn)\n",
    "df_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dataset range\n",
    "print('Time Range of the Dataset is between:', df_d['origintimeutc'].min(), 'and', df_d['origintimeutc'].max())\n",
    "\n",
    "print(\"\\ndf.columns:\\n\", df_d.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b4695",
   "metadata": {},
   "source": [
    "## PART 5. Data Re-treatment and Export Data Table in HTML format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb48ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Re-treatment of the dataset\n",
    "df_d['origintimeutc'] = df_d['origintimeutc'].apply(lambda x: dt.datetime.strptime(x,'%Y/%m/%d %H:%M:%S') if type(x)==str else pd.NaT)\n",
    "df_d['magnitude'] = df_d['magnitude'].astype('float')\n",
    "df_d['magtype'] = df_d['magtype'].astype('string')\n",
    "\n",
    "df_d['latitude'] = df_d['latitude'].astype(str).map(lambda x: x.rstrip('° N').rstrip('° S'))\n",
    "df_d['longitude'] = df_d['longitude'].astype(str).map(lambda x: x.rstrip('° E').rstrip('° W'))\n",
    "df_d['depthkm'] = df_d['depthkm'].replace('-', 0).astype(\"float\")\n",
    "\n",
    "df_d['region'] = df_d['region'].astype('string')\n",
    "df_d['measmethod'] = df_d['measmethod'].astype('string')\n",
    "df_d['updtime'] = df_d['updtime'].apply(lambda x: dt.datetime.strptime(x,'%Y/%m/%d %H:%M:%S') if type(x)==str else pd.NaT)\n",
    "df_d['attribute'] = df_d['attribute'].astype('string')\n",
    "\n",
    "# Adjust datetime from UTC (GMT) to Turkey timezone (GMT+3)\n",
    "df_d['eventtime'] = df_d['origintimeutc'] + pd.DateOffset(hours=3)\n",
    "df_d['updtime'] = df_d['updtime'] + pd.DateOffset(hours=3)\n",
    "df_d['eventtime'] = pd.to_datetime(df_d['eventtime'])\n",
    "df_d['updtime'] = pd.to_datetime(df_d['updtime'])\n",
    "\n",
    "\n",
    "# Create new columns for date and time\n",
    "df_d['date'] = pd.to_datetime(df_d['eventtime']).dt.date\n",
    "df_d['time'] = pd.to_datetime(df_d['eventtime']).dt.time\n",
    "\n",
    "# take a look\n",
    "df_d.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive data table using Dtale - Big fun, isn't it?\n",
    "import dtale\n",
    "dtale.show(df_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763976b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preapre Data for exporting to a Data Table\n",
    "\n",
    "# Select columns\n",
    "df_tbl = df_d[['eventtime', 'magnitude', 'magtype', 'latitude', 'longitude', 'depthkm', 'region', 'measmethod', 'updtime', 'attribute']]\n",
    "df_tbl.columns = ['eventTime', 'magnitude', 'magType', 'latitude', 'longitude', 'depthKm', 'region', 'measMethod', 'updTime', 'attribute']\n",
    "# Change the default Ascending to Descending to put newest datapoints on the top of the data table\n",
    "df_tbl_1 = df_tbl.sort_values(by='eventTime', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c24b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-making Interactive Data Table using JQuery\n",
    "def generate_html(dataframe: pd.DataFrame):\n",
    "    # get the table HTML from the dataframe\n",
    "    table_html = dataframe.to_html(table_id=\"table\")\n",
    "    # construct the complete HTML with jQuery Data tables\n",
    "    # You can disable paging or enable y scrolling on lines 20 and 21 respectively\n",
    "    html = f\"\"\"\n",
    "    <html>\n",
    "    <header>\n",
    "        <link href=\"https://cdn.datatables.net/1.11.5/css/jquery.dataTables.min.css\" rel=\"stylesheet\">\n",
    "    </header>\n",
    "    <body>\n",
    "    {table_html}\n",
    "    <script src=\"https://code.jquery.com/jquery-3.6.0.slim.min.js\" integrity=\"sha256-u7e5khyithlIdTpu22PHhENmPcRdFiHRjhAuHcs05RI=\" crossorigin=\"anonymous\"></script>\n",
    "    <script type=\"text/javascript\" src=\"https://cdn.datatables.net/1.11.5/js/jquery.dataTables.min.js\"></script>\n",
    "    <script>\n",
    "        $(document).ready( function () {{\n",
    "            $('#table').DataTable({{\n",
    "                order: [[0, 'desc']],\n",
    "                lengthMenu: [20, 50, 100, 200],\n",
    "                pageLength: 20,\n",
    "                paging: true,\n",
    "            }});\n",
    "        }});\n",
    "    </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    # return the html\n",
    "    return html\n",
    "\n",
    "# Give a go\n",
    "table_interact = generate_html(df_tbl_1)\n",
    "with open(\"web/table_interact_koeri.html\", 'w') as f:\n",
    "    f.write(table_interact)\n",
    "webbrowser.open(os.getcwd() + \"../web/table_interact_koeri.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc638daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another Pretty HTML Data Table\n",
    "from pretty_html_table import build_table\n",
    "\n",
    "html_table_bluelight = build_table(df_tbl_1, 'blue_light',\n",
    "                                   font_size='medium',\n",
    "                                   font_family='Arial',\n",
    "                                   text_align='center',\n",
    "                                   width='auto',\n",
    "                                   index=False,\n",
    "                                   conditions={\n",
    "                                        'magnitude': {\n",
    "                                        'min': 3.0,\n",
    "                                        'max': 9.0,\n",
    "                                        'mix_color': 'green',\n",
    "                                        'max_color': 'red'\n",
    "                                        }\n",
    "                                   },\n",
    "                                   even_color='black',\n",
    "                                   even_bg_color='white'\n",
    "                                   )\n",
    "\n",
    "# center the table using HTML formatting\n",
    "html_table_bluelight = '<div style=\"text-align:center\">' + html_table_bluelight + '</div>'\n",
    "\n",
    "# write the HTML table to a file\n",
    "with open('web/table_bluelight_koeri.html', 'w') as f:\n",
    "    f.write(html_table_bluelight)\n",
    "webbrowser.open(os.getcwd() + \"../web/table_bluelight_koeri.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37926323",
   "metadata": {},
   "source": [
    "## PART 6. Export Maps\n",
    "\n",
    "### 6.1 Bubble Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a31190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the df and rename the columns\n",
    "df_d2 = df_d[['date', 'time', 'latitude', 'longitude', 'depthkm', 'magnitude', 'magtype', 'region', 'measmethod', 'eventtime', 'updtime', 'attribute']]\n",
    "df_d2.head()\n",
    "# print the earthquake with magnitude >=4\n",
    "print(df_d2[df_d2['magnitude'].astype('float') >= 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ec5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our functions\n",
    "# Func 1 - Proportionize the fill_color against magnitude\n",
    "myColorScheme = ['green', 'red', 'black']\n",
    "def get_color(magnitude):\n",
    "    if magnitude <= 3:\n",
    "        return myColorScheme[0]\n",
    "    elif magnitude <= 6:\n",
    "        return myColorScheme[1]\n",
    "    else:\n",
    "        return myColorScheme[2]\n",
    "\n",
    "# Func 2 - addCircles\n",
    "popwidth, popht = 250, 150\n",
    "def addCircles(df, map):\n",
    "    for x, y, mag, region, date, time in zip(df['latitude'], df['longitude'], df['magnitude'], df['region'], df['date'], df['time']):\n",
    "        popUp = f\"<p style='text-align: center;'><span style='font-family: Verdana, Geneva, sans-serif; font-size: 12px; color: rgb(40, 50, 78);'><strong>Magnitude: {mag} </strong></span></p>\" \\\n",
    "                f\"<p style='text-align: center;'><span style='font-family: Verdana, Geneva, sans-serif; font-size: 12px; color: rgb(40, 50, 78);'><strong>Region: {region}</strong></span></p>\" \\\n",
    "                f\"<p style='text-align: center;'><span style='font-family: Verdana, Geneva, sans-serif; font-size: 12px; color: rgb(40, 50, 78);'><strong>Date: {date}</strong></span></p>\" \\\n",
    "                f\"<p style='text-align: center;'><span style='font-family: Verdana, Geneva, sans-serif; font-size: 12px; color: rgb(40, 50, 78);'><strong>Time: {time}</strong></span></p>\"\n",
    "        iframe = folium.IFrame(popUp, width=popwidth, height=popht)\n",
    "        popup = folium.Popup(iframe, max_width=450)\n",
    "        folium.CircleMarker(location=(x, y), radius=float(mag) * 4, weight=2, opacity=1, popup=popup,\n",
    "                            color=get_color(mag), fill_color=get_color(mag), fill_opacity=0.6).add_to(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aabbd0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Map Parameters\n",
    "magThreshold = 4\n",
    "mapCtr = [39.16, 35.66]\n",
    "\n",
    "# Initial Map\n",
    "bubbleMap = folium.Map(location=mapCtr, zoom_start=6, tiles=None)\n",
    "\n",
    "# Load up the tectonic polygon (in GeoJson format)\n",
    "# Original URL - https://raw.githubusercontent.com/fraxen/tectonicplates/master/GeoJSON/PB2002_boundaries.json\n",
    "folium.GeoJson('data/PB2002_boundaries.json', name=\"Tectonic Boundaries\").add_to(bubbleMap)\n",
    "\n",
    "# Add tiles with custom names (The first tile will be the default)\n",
    "folium.TileLayer('Stamen Terrain', name='Terrian').add_to(bubbleMap)\n",
    "folium.TileLayer('openstreetmap', name='Open Street').add_to(bubbleMap)\n",
    "folium.TileLayer('Stamen Toner', name='Toner').add_to(bubbleMap)\n",
    "folium.TileLayer('Stamen Water Color', name='Water Color').add_to(bubbleMap)\n",
    "folium.TileLayer('cartodbdark_matter', name='Dark Matter').add_to(bubbleMap)\n",
    "folium.LayerControl().add_to(bubbleMap)\n",
    "\n",
    "# Map Data filtering\n",
    "earthquakeDF = df_d2[df_d2['magnitude'].astype('float') >= magThreshold]\n",
    "\n",
    "# add Circles (sizing per magnitude)\n",
    "addCircles(earthquakeDF, bubbleMap)\n",
    "\n",
    "# Add lenend to the bubble map\n",
    "from branca.colormap import StepColormap\n",
    "magMin, magLow, magHigh, magMax = 0, 3, 6, 10\n",
    "mySteps = [magMin, magLow, magHigh, magMax]\n",
    "\n",
    "# myColorScheme has been defined previously\n",
    "legend_bar = StepColormap(colors=myColorScheme,\n",
    "                          index=mySteps,\n",
    "                          vmin=magMin, vmax=magMax,\n",
    "                          tick_labels = mySteps)\n",
    "legend_bar.caption = 'Magnitude Scale'\n",
    "legend_bar.add_to(bubbleMap)\n",
    "\n",
    "# More widgets\n",
    "bubbleMap.add_child(folium.LatLngPopup())\n",
    "bubbleMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecfc4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Eventually save map to interactive HTML file and display in the browser\n",
    "bubbleMap.save(\"web/map_bubble_koeri.html\")\n",
    "webbrowser.open(os.getcwd() + \"../web/map_bubble_koeri.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f94b2",
   "metadata": {},
   "source": [
    "### 6.2 Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f179c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Heat Map\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Make a list of heatMapData\n",
    "heatMapData = earthquakeDF[['latitude', 'longitude', 'magnitude']]\n",
    "\n",
    "# Create the HeatMap - \"CartoDB Dark_Matter\" is the default tile for heat map\n",
    "heatMap = folium.Map(mapCtr, tiles=\"Stamen Terrain\", zoom_start=6)\n",
    "# More widgets\n",
    "heatMap.add_child(folium.LatLngPopup())\n",
    "\n",
    "# Create heat map\n",
    "plugins.HeatMap(heatMapData, \n",
    "                name=\"Magnitude\", \n",
    "                radius=earthquakeDF['magnitude'].mean()*3,\n",
    "                min_opacity = 1,\n",
    "                max_zoom=15,\n",
    "                blur=20,\n",
    "                overlay=False,\n",
    "                control=False,\n",
    "                show=True\n",
    "                ).add_to(heatMap)\n",
    "\n",
    "# Create a toolbar using ipywidgets in Jupyter Notebook\n",
    "toolbar_left = widgets.HTML(\n",
    "    value='<h3 style=\"text-align:left; background-color: purple; color: white\">Turkey Earthquake Monitoring System - Heat Map</h3>',\n",
    "    layout=widgets.Layout(width='70%', height='50px')\n",
    ")\n",
    "toolbar_right = widgets.HTML(\n",
    "    value='<h3 style=\"text-align:right; background-color: light-grey; color: blue\"> \\\n",
    "    <a href=\"output/map_bubble_koeri.html\" target=\"_blank\">Switch to Bubble Map</a></h3>',\n",
    "    layout=widgets.Layout(width='30%', height='50px')\n",
    ")\n",
    "\n",
    "toolbar = widgets.HBox([toolbar_left, toolbar_right])\n",
    "\n",
    "# Display the toolbar and the map together using IPython.display\n",
    "display(toolbar)\n",
    "display(heatMap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd8958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Heatmap and display in the browser\n",
    "heatMap.save(\"web/map_heat_koeri.html\")\n",
    "webbrowser.open(os.getcwd() + \"../web/map_heat_koeri.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8345f7e6",
   "metadata": {},
   "source": [
    "### 6.3 Choropleth Map\n",
    "\n",
    "__Per Wikipedia__\n",
    "\n",
    "A choropleth map (from Greek χῶρος (choros) 'area/region', and πλῆθος (plethos) 'multitude') is a type of statistical thematic map that uses pseudocolor, i.e., color corresponding with an aggregate summary of a geographic characteristic within spatial enumeration units, such as population density or per-capita income."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f0fdd",
   "metadata": {},
   "source": [
    "```\n",
    "#####  The data sample have issue, then disable this for now\n",
    "# Map Parameters\n",
    "magThreshold = 4\n",
    "mapCtr = [39.16, 35.66]\n",
    "\n",
    "# Load up the turkey provinces polygon (in GeoJson format)\n",
    "province_geo = pd.read_json('data/geoboundaries-TUR-ADM1_simplified.json')\n",
    "province_data = pd.read_csv(\"data/geodata-TUR-ADM1_mag_sum_avg.csv\")\n",
    "#province_data.columns\n",
    "\n",
    "merged_data = province_geo.merge(province_data, left_on='shapeISO', right_on='shapeISO')\n",
    "\n",
    "# Initial Map\n",
    "choropMap = folium.Map(location=mapCtr, zoom_start=5)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=merged_data,\n",
    "    name=\"choropleth Map of Turkey Earthquake\",\n",
    "    data=merged_data,\n",
    "    columns=[\"shapeISO\", \"magSum\"],\n",
    "    key_on=\"feature.properties.shapeISO\",\n",
    "    fill_color=\"YlGn\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name=\"Earthquake Magnitude sum per Province\",\n",
    ").add_to(choropMap)\n",
    "\n",
    "folium.LayerControl().add_to(choropMap)\n",
    "\n",
    "choropMap\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c74439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase of Reverse Geocoding\n",
    "import reverse_geocoder as rg\n",
    "g = rg.search(mapCtr)\n",
    "print(g) # g is a list with one dictionary\n",
    "print('City:', g[0]['name'], '| Province:', g[0]['admin1'], '| Country:', g[0]['cc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d3cfd",
   "metadata": {},
   "source": [
    "##### Function 3 - Reverse Geocoding - Takes 51 minutes, then comments out for this moment\n",
    "```\n",
    "import reverse_geocoder as rg\n",
    "def get_location(row):\n",
    "    coordinates = (row['latitude'], row['longitude'])\n",
    "    result = rg.search(coordinates)[0]\n",
    "    return result['name'], result['admin1'], result['cc']\n",
    "\n",
    "df2[['city', 'state', 'country']] = df2.apply(get_location, axis=1, result_type='expand')\n",
    "\n",
    "df2\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63d5e045",
   "metadata": {},
   "source": [
    "## 6.4 Time-Slider Choropleth Map\n",
    "\n",
    "Folium is a Python library for creating interactive maps. It allows you to create maps with different types of markers, shapes, and layers. Folium also provides a way to add a time slider to your maps, which allows you to display data over time.\n",
    "\n",
    "To add a time slider to your Folium map, you can use the plugins.TimestampedGeoJson class. This class takes a GeoJSON object as input, along with a date field that indicates the time for each feature in the GeoJSON object. Here's an example of how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee670eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Data filtering\n",
    "df_d = df_d[df_d['magnitude'].astype('float') >= 4]\n",
    "df_d.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Create a sample DataFrame with latitude, longitude, and time columns\n",
    "geo_data = df_d[['latitude', 'longitude', 'magnitude', 'depthkm', 'region', 'date']]\n",
    "geo_data.reset_index(drop=True, inplace=True)\n",
    "geo_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f28e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(geo_data, geometry=gpd.points_from_xy(geo_data.longitude, geo_data.latitude))\n",
    "gdf.crs = 'EPSG:4326'\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db86723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import TimeSliderChoropleth\n",
    "import pandas as pd\n",
    "\n",
    "# Create map object\n",
    "mapCtr = [39.16, 35.66]\n",
    "\n",
    "m = folium.Map(location=mapCtr, zoom_start=6)\n",
    "\n",
    "gdf['date'] = pd.to_datetime(gdf['date'], format = '%Y-%m-%d')\n",
    "\n",
    "gdf['date'] = pd.to_datetime(gdf['date'], errors='coerce')\n",
    "gdf = gdf.dropna(subset=['date', 'geometry'])\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf.columns)\n",
    "gdf = gdf.set_index('date')\n",
    "print(gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd5f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "style_dict = {'fillColor': {'property': 'my_property', 'scale': 'YlOrRd', 'domain': [0, 1]},\n",
    "              'fillOpacity': {'value': 0.5},\n",
    "              'weight': {'value': 0}}\n",
    "\n",
    "g = TimeSliderChoropleth(\n",
    "    gdf,\n",
    "    styledict=style_dict,\n",
    ").add_to(m)\n",
    "\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f3b5ec",
   "metadata": {},
   "source": [
    "## PART 7. Bootstrap the Landing page and Other pages\n",
    "\n",
    "This has been done by bootstraping a very simple landing page, consisting of:\n",
    "* a Toolbar with\n",
    "    * Home\n",
    "    * Data Table\n",
    "    * Bubble Map\n",
    "    * Heat Map\n",
    "    * Project\n",
    "* a Map container, where\n",
    "    * the content shall be switched over from one to another once visitor clicks the links on the toolbar;\n",
    "    * a default page shall be loaded one the website is open.\n",
    "\n",
    "So far, all look good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9b5329",
   "metadata": {},
   "source": [
    "## The END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7e17b399900b383235e9fd26e7a153e6c4c8790701ed3e70443ac3efa33d234"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
